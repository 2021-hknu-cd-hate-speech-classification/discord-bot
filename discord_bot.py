import discord
import torch
from hate_speech_classification_model import HateSpeechClassifier

# https://discord.com/api/oauth2/authorize?client_id=823899168942456922&permissions=8258&scope=bot


def get_env(name: str) -> str:
    import os

    try:
        result = os.environ[name]
    except KeyError:
        result = ""

    return result


client = discord.Client()
token = get_env("DISCORD_TOKEN")

MODEL_PATH = get_env("MODEL_PATH")
model: HateSpeechClassifier = torch.load(MODEL_PATH, map_location="cpu")

@client.event
async def on_ready():
    print("login")


@client.event
async def on_message(message):
    if message.author.bot:
        return None

    if message.content.startswith("!"):
        await message.add_reaction("â­ï¸")
        return None

    if len(message.content) >= 5:
        score = model.infer(message.content)
        print(message.content, float(score[1]))
        await message.add_reaction(f"{int(score[1] * 10)}\uFE0F\u20E3")

        if score[1] >= 0.7:
            await message.add_reaction("ğŸ¤¬")

    else:
        await message.add_reaction("ğŸ˜‘")

    return None

    # if score[0][1] > threshold_score:
    #     # ë©”ì‹œì§€ë¥¼ ì‚­ì œí•œ í›„ ì•ˆë‚´
    #     noti = discord.Embed()
    #     noti.title = "ë©”ì‹œì§€ ì‚­ì œ ì•ˆë‚´"
    #     noti.description = f"ë©”ì‹œì§€ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. ì ìˆ˜ê°€ {threshold_score}ì  ì´ìƒì¼ ê²½ìš° ì‚­ì œë©ë‹ˆë‹¤."
    #     noti.colour = 0xd32f2f
    #     noti.add_field(name="ë©”ì‹œì§€ ë‚´ìš©", value=message.content, inline=False)
    #     noti.add_field(name="ì ìˆ˜", value=str(score.tolist()), inline=False)
    #     noti.add_field(name="ì‘ì„± ì‹œê°„(UTC)", value=message.created_at.strftime("%Y-%m-%d %H:%M:%S"))
    #     noti.add_field(name="ì‘ì„±ì", value=message.author.display_name)
    #     await message.delete()
    #     await message.channel.send(embed=noti)
    # elif score[0][1] > threshold_score - 0.1:
    #     await message.add_reaction("ğŸ¤¬")
    #     return None

client.run(token)
